{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "486b6ecf-15e1-41ff-93cc-6f15628ee631",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap_external>:1184: FutureWarning: The cuda.cudart module is deprecated and will be removed in a future release, please switch to use the cuda.bindings.runtime module instead.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from monai.networks.schedulers import DDPMScheduler\n",
    "from monai.inferers.inferer import DiffusionInferer\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "import pandas as pd\n",
    "from monai.bundle import ConfigParser\n",
    "import nibabel as nib\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "#%% Setup device\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df6865ff-7b80-4775-a956-79fc4e311972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup paths to uploaded training data\n",
    "training_dataset = 'TrainingData_Key/slices_40_anon'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f79ca9f-7fae-46ea-bddd-a9c985bfc10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup paths to uploaded config files\n",
    "config_path_ = 'Configs/configs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9422838a-dcd4-41f2-be3b-1f298b7a1e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_path = 'trained_vAE_epoch_148.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4708c5b8-0c99-4c6c-a22e-32a594ecd3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets(df, data_dir):\n",
    "\n",
    "    df['Linked_Files_Anon'] = df['Linked_Files_Anon'].apply(lambda x: os.path.join(data_dir, x))\n",
    "\n",
    "    train_data = df[df['Set']=='Train']\n",
    "    valid_data = df[df['Set']=='Validation']\n",
    "    test_data = df[df['Set']=='Test']\n",
    "\n",
    "    train_data = train_data.reset_index()\n",
    "    valid_data = valid_data.reset_index()\n",
    "    test_data = test_data.reset_index()\n",
    "\n",
    "    train_dataset = FDG_Dataset(data=train_data)\n",
    "    valid_dataset = FDG_Dataset(data=valid_data)\n",
    "    test_dataset = FDG_Dataset(data=test_data)\n",
    "\n",
    "    return train_dataset, valid_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7b2c331-fa06-4931-8c43-cd0e0a9cbde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FDG_Dataset(Dataset):\n",
    "    \"\"\"\n",
    "    A PyTorch Dataset to load NIfTI files from a provided list of file paths.\n",
    "    \"\"\"\n",
    "    def __init__(self, data):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            file_paths (list of Path objects): List of paths to the NIfTI files.\n",
    "        \"\"\"\n",
    "\n",
    "        self.csv = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.csv)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        diag = self.csv.loc[idx, 'DX_encoded']\n",
    "        file_name = self.csv.loc[idx, 'Linked_Files_Anon']\n",
    "\n",
    "        nii_img  = nib.load(file_name)\n",
    "        nii_data = nii_img.get_fdata()\n",
    "\n",
    "        nii_data_scaled = (nii_data - nii_data.min())/(nii_data.max() - nii_data.min())\n",
    "        image_tensor = torch.from_numpy(nii_data_scaled)\n",
    "\n",
    "        return image_tensor, diag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5600518a-2f7c-4f1e-9158-b17eb14c7d2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoencoderKL(\n",
       "  (encoder): Encoder(\n",
       "    (blocks): ModuleList(\n",
       "      (0): Convolution(\n",
       "        (conv): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (1-2): 2 x AEKLResBlock(\n",
       "        (norm1): GroupNorm(32, 64, eps=1e-06, affine=True)\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (norm2): GroupNorm(32, 64, eps=1e-06, affine=True)\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (nin_shortcut): Identity()\n",
       "      )\n",
       "      (3): AEKLDownsample(\n",
       "        (pad): AsymmetricPad()\n",
       "        (conv): Convolution(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2))\n",
       "        )\n",
       "      )\n",
       "      (4): AEKLResBlock(\n",
       "        (norm1): GroupNorm(32, 64, eps=1e-06, affine=True)\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (nin_shortcut): Convolution(\n",
       "          (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (5): AEKLResBlock(\n",
       "        (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (nin_shortcut): Identity()\n",
       "      )\n",
       "      (6): AEKLDownsample(\n",
       "        (pad): AsymmetricPad()\n",
       "        (conv): Convolution(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2))\n",
       "        )\n",
       "      )\n",
       "      (7): AEKLResBlock(\n",
       "        (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (nin_shortcut): Convolution(\n",
       "          (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (8-9): 2 x AEKLResBlock(\n",
       "        (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (nin_shortcut): Identity()\n",
       "      )\n",
       "      (10): SpatialAttentionBlock(\n",
       "        (norm): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "        (attn): SABlock(\n",
       "          (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (to_q): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (to_k): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (to_v): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (qkv): Identity()\n",
       "          (input_rearrange): Rearrange('b h (l d) -> b l h d', l=1)\n",
       "          (out_rearrange): Rearrange('b l h d -> b h (l d)')\n",
       "          (drop_output): Dropout(p=0.0, inplace=False)\n",
       "          (drop_weights): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): AEKLResBlock(\n",
       "        (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (nin_shortcut): Identity()\n",
       "      )\n",
       "      (12): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "      (13): Convolution(\n",
       "        (conv): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (blocks): ModuleList(\n",
       "      (0): Convolution(\n",
       "        (conv): Conv2d(1, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (1): AEKLResBlock(\n",
       "        (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (nin_shortcut): Identity()\n",
       "      )\n",
       "      (2): SpatialAttentionBlock(\n",
       "        (norm): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "        (attn): SABlock(\n",
       "          (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (to_q): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (to_k): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (to_v): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (qkv): Identity()\n",
       "          (input_rearrange): Rearrange('b h (l d) -> b l h d', l=1)\n",
       "          (out_rearrange): Rearrange('b l h d -> b h (l d)')\n",
       "          (drop_output): Dropout(p=0.0, inplace=False)\n",
       "          (drop_weights): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3-5): 3 x AEKLResBlock(\n",
       "        (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (nin_shortcut): Identity()\n",
       "      )\n",
       "      (6): UpSample(\n",
       "        (upsample_non_trainable): Upsample(scale_factor=(2.0, 2.0), mode='nearest')\n",
       "        (postconv): Convolution(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (7): AEKLResBlock(\n",
       "        (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (nin_shortcut): Convolution(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (8): AEKLResBlock(\n",
       "        (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (nin_shortcut): Identity()\n",
       "      )\n",
       "      (9): UpSample(\n",
       "        (upsample_non_trainable): Upsample(scale_factor=(2.0, 2.0), mode='nearest')\n",
       "        (postconv): Convolution(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (10): AEKLResBlock(\n",
       "        (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (norm2): GroupNorm(32, 64, eps=1e-06, affine=True)\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (nin_shortcut): Convolution(\n",
       "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (11): AEKLResBlock(\n",
       "        (norm1): GroupNorm(32, 64, eps=1e-06, affine=True)\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (norm2): GroupNorm(32, 64, eps=1e-06, affine=True)\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (nin_shortcut): Identity()\n",
       "      )\n",
       "      (12): GroupNorm(32, 64, eps=1e-06, affine=True)\n",
       "      (13): Convolution(\n",
       "        (conv): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (quant_conv_mu): Convolution(\n",
       "    (conv): Conv2d(1, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (quant_conv_log_sigma): Convolution(\n",
       "    (conv): Conv2d(1, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (post_quant_conv): Convolution(\n",
       "    (conv): Conv2d(1, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Config filename\n",
    "config_file=\"train_autoencoder.json\"\n",
    "\n",
    "# Weights Filename\n",
    "weights_file=\"trained_vAE_epoch_148.pt\"\n",
    "\n",
    "# Setup config filepath\n",
    "config_path = os.path.join(config_path_, config_file)\n",
    "\n",
    "# Setup weights filepath\n",
    "weights_path = os.path.join(pretrained_path, weights_file)\n",
    "\n",
    "# Read config\n",
    "config = ConfigParser()\n",
    "config.read_config(config_path)\n",
    "\n",
    "# Parse model\n",
    "vAE_model = config.get_parsed_content(\"gnetwork\")\n",
    "\n",
    "# Load checkpoint\n",
    "checkpoint = torch.load(weights_path, map_location=device)\n",
    "\n",
    "# Key remapping\n",
    "key_mapping = {\n",
    "    \"encoder.blocks.10.to_q.weight\": \"encoder.blocks.10.attn.to_q.weight\",\n",
    "    \"encoder.blocks.10.to_q.bias\": \"encoder.blocks.10.attn.to_q.bias\",\n",
    "    \"encoder.blocks.10.to_k.weight\": \"encoder.blocks.10.attn.to_k.weight\",\n",
    "    \"encoder.blocks.10.to_k.bias\": \"encoder.blocks.10.attn.to_k.bias\",\n",
    "    \"encoder.blocks.10.to_v.weight\": \"encoder.blocks.10.attn.to_v.weight\",\n",
    "    \"encoder.blocks.10.to_v.bias\": \"encoder.blocks.10.attn.to_v.bias\",\n",
    "    \"encoder.blocks.10.proj_attn.weight\": \"encoder.blocks.10.attn.out_proj.weight\",\n",
    "    \"encoder.blocks.10.proj_attn.bias\": \"encoder.blocks.10.attn.out_proj.bias\",\n",
    "    \"decoder.blocks.2.to_q.weight\": \"decoder.blocks.2.attn.to_q.weight\",\n",
    "    \"decoder.blocks.2.to_q.bias\": \"decoder.blocks.2.attn.to_q.bias\",\n",
    "    \"decoder.blocks.2.to_k.weight\": \"decoder.blocks.2.attn.to_k.weight\",\n",
    "    \"decoder.blocks.2.to_k.bias\": \"decoder.blocks.2.attn.to_k.bias\",\n",
    "    \"decoder.blocks.2.to_v.weight\": \"decoder.blocks.2.attn.to_v.weight\",\n",
    "    \"decoder.blocks.2.to_v.bias\": \"decoder.blocks.2.attn.to_v.bias\",\n",
    "    \"decoder.blocks.2.proj_attn.weight\": \"decoder.blocks.2.attn.out_proj.weight\",\n",
    "    \"decoder.blocks.2.proj_attn.bias\": \"decoder.blocks.2.attn.out_proj.bias\",\n",
    "    \"decoder.blocks.6.conv.conv.weight\": \"decoder.blocks.6.postconv.conv.weight\",\n",
    "    \"decoder.blocks.6.conv.conv.bias\": \"decoder.blocks.6.postconv.conv.bias\",\n",
    "    \"decoder.blocks.9.conv.conv.weight\": \"decoder.blocks.9.postconv.conv.weight\",\n",
    "    \"decoder.blocks.9.conv.conv.bias\": \"decoder.blocks.9.postconv.conv.bias\",\n",
    "}\n",
    "\n",
    "# Remap keys\n",
    "new_state_dict = {key_mapping.get(k, k): v for k, v in checkpoint.items()}\n",
    "\n",
    "# Load state\n",
    "vAE_model.load_state_dict(new_state_dict, strict=False)\n",
    "vAE_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ab136fd-9a8c-4bd1-99df-8aaf1388f853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config file\n",
    "config_file=\"train_cond_diffusion.json\"\n",
    "\n",
    "# Setup config filepath\n",
    "config_path = os.path.join(config_path_, config_file)\n",
    "\n",
    "# Read config\n",
    "config = ConfigParser()\n",
    "config.read_config(config_path)\n",
    "\n",
    "# Parse model\n",
    "LDM_model = config.get_parsed_content(\"diffusion\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5eae0077-0275-4e79-b82b-a00621267693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets / Dataloader\n",
    "data = os.path.join('TrainingData_Key/data_key_anon.csv')\n",
    "data = pd.read_csv(data)\n",
    "train_dataset, valid_dataset, test_dataset = create_datasets(data, training_dataset)\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, persistent_workers=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, num_workers=4, persistent_workers=True)\n",
    "\n",
    "# Epochs\n",
    "training_epochs = 500\n",
    "\n",
    "# Learning rate\n",
    "init_lr = 5e-05\n",
    "fin_lr = 1e-08\n",
    "# Optimizer\n",
    "optimiser = optim.Adam(LDM_model.parameters(), lr=init_lr)\n",
    "# Learning rate scheduler\n",
    "#lr_scheduler = CombinedScheduler(optimiser, 1, training_epochs, 20, init_lr, fin_lr)\n",
    "\n",
    "# LDM Scheduler\n",
    "ldm_scheduler = DDPMScheduler(schedule=\"scaled_linear_beta\", num_train_timesteps=1000, beta_start=0.0015, beta_end= 0.0195)\n",
    "\n",
    "# Inferer\n",
    "inferer = DiffusionInferer(ldm_scheduler)\n",
    "\n",
    "# Output folder\n",
    "output_folder = '/content/output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c0e197b-c044-408b-bebc-00fab88896a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DiffusionModelUNet(\n",
       "  (conv_in): Convolution(\n",
       "    (conv): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (time_embed): Sequential(\n",
       "    (0): Linear(in_features=32, out_features=128, bias=True)\n",
       "    (1): SiLU()\n",
       "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       "  (down_blocks): ModuleList(\n",
       "    (0): DownBlock(\n",
       "      (resnets): ModuleList(\n",
       "        (0-1): 2 x DiffusionUNetResnetBlock(\n",
       "          (norm1): GroupNorm(32, 32, eps=1e-06, affine=True)\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv1): Convolution(\n",
       "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (time_emb_proj): Linear(in_features=128, out_features=32, bias=True)\n",
       "          (norm2): GroupNorm(32, 32, eps=1e-06, affine=True)\n",
       "          (conv2): Convolution(\n",
       "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Identity()\n",
       "        )\n",
       "      )\n",
       "      (downsampler): DiffusionUnetDownsample(\n",
       "        (op): Convolution(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): CrossAttnDownBlock(\n",
       "      (attentions): ModuleList(\n",
       "        (0-1): 2 x SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 64, eps=1e-06, affine=True)\n",
       "          (proj_in): Convolution(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): DiffusionUNetTransformerBlock(\n",
       "              (attn1): SABlock(\n",
       "                (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "                (to_q): Linear(in_features=64, out_features=64, bias=False)\n",
       "                (to_k): Linear(in_features=64, out_features=64, bias=False)\n",
       "                (to_v): Linear(in_features=64, out_features=64, bias=False)\n",
       "                (qkv): Identity()\n",
       "                (input_rearrange): Rearrange('b h (l d) -> b l h d', l=2)\n",
       "                (out_rearrange): Rearrange('b l h d -> b h (l d)')\n",
       "                (drop_output): Dropout(p=0.0, inplace=False)\n",
       "                (drop_weights): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (ff): MLPBlock(\n",
       "                (linear1): Linear(in_features=64, out_features=512, bias=True)\n",
       "                (linear2): Linear(in_features=256, out_features=64, bias=True)\n",
       "                (fn): GEGLU()\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (attn2): CrossAttentionBlock(\n",
       "                (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "                (to_q): Linear(in_features=64, out_features=64, bias=False)\n",
       "                (to_k): Linear(in_features=1, out_features=64, bias=False)\n",
       "                (to_v): Linear(in_features=1, out_features=64, bias=False)\n",
       "                (input_rearrange): Rearrange('b h (l d) -> b l h d', l=2)\n",
       "                (out_rearrange): Rearrange('b l h d -> b h (l d)')\n",
       "                (drop_output): Dropout(p=0.0, inplace=False)\n",
       "                (drop_weights): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Convolution(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (resnets): ModuleList(\n",
       "        (0): DiffusionUNetResnetBlock(\n",
       "          (norm1): GroupNorm(32, 32, eps=1e-06, affine=True)\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv1): Convolution(\n",
       "            (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (time_emb_proj): Linear(in_features=128, out_features=64, bias=True)\n",
       "          (norm2): GroupNorm(32, 64, eps=1e-06, affine=True)\n",
       "          (conv2): Convolution(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Convolution(\n",
       "            (conv): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (1): DiffusionUNetResnetBlock(\n",
       "          (norm1): GroupNorm(32, 64, eps=1e-06, affine=True)\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv1): Convolution(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (time_emb_proj): Linear(in_features=128, out_features=64, bias=True)\n",
       "          (norm2): GroupNorm(32, 64, eps=1e-06, affine=True)\n",
       "          (conv2): Convolution(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Identity()\n",
       "        )\n",
       "      )\n",
       "      (downsampler): DiffusionUnetDownsample(\n",
       "        (op): Convolution(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): CrossAttnDownBlock(\n",
       "      (attentions): ModuleList(\n",
       "        (0-1): 2 x SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "          (proj_in): Convolution(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): DiffusionUNetTransformerBlock(\n",
       "              (attn1): SABlock(\n",
       "                (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (to_q): Linear(in_features=128, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=128, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=128, out_features=128, bias=False)\n",
       "                (qkv): Identity()\n",
       "                (input_rearrange): Rearrange('b h (l d) -> b l h d', l=4)\n",
       "                (out_rearrange): Rearrange('b l h d -> b h (l d)')\n",
       "                (drop_output): Dropout(p=0.0, inplace=False)\n",
       "                (drop_weights): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (ff): MLPBlock(\n",
       "                (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "                (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
       "                (fn): GEGLU()\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (attn2): CrossAttentionBlock(\n",
       "                (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (to_q): Linear(in_features=128, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=1, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=1, out_features=128, bias=False)\n",
       "                (input_rearrange): Rearrange('b h (l d) -> b l h d', l=4)\n",
       "                (out_rearrange): Rearrange('b l h d -> b h (l d)')\n",
       "                (drop_output): Dropout(p=0.0, inplace=False)\n",
       "                (drop_weights): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Convolution(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (resnets): ModuleList(\n",
       "        (0): DiffusionUNetResnetBlock(\n",
       "          (norm1): GroupNorm(32, 64, eps=1e-06, affine=True)\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv1): Convolution(\n",
       "            (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (time_emb_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "          (conv2): Convolution(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Convolution(\n",
       "            (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (1): DiffusionUNetResnetBlock(\n",
       "          (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv1): Convolution(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (time_emb_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "          (conv2): Convolution(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Identity()\n",
       "        )\n",
       "      )\n",
       "      (downsampler): DiffusionUnetDownsample(\n",
       "        (op): Convolution(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): CrossAttnDownBlock(\n",
       "      (attentions): ModuleList(\n",
       "        (0-1): 2 x SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "          (proj_in): Convolution(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): DiffusionUNetTransformerBlock(\n",
       "              (attn1): SABlock(\n",
       "                (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (to_q): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (to_k): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (to_v): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (qkv): Identity()\n",
       "                (input_rearrange): Rearrange('b h (l d) -> b l h d', l=8)\n",
       "                (out_rearrange): Rearrange('b l h d -> b h (l d)')\n",
       "                (drop_output): Dropout(p=0.0, inplace=False)\n",
       "                (drop_weights): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (ff): MLPBlock(\n",
       "                (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "                (linear2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "                (fn): GEGLU()\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (attn2): CrossAttentionBlock(\n",
       "                (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (to_q): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (to_k): Linear(in_features=1, out_features=256, bias=False)\n",
       "                (to_v): Linear(in_features=1, out_features=256, bias=False)\n",
       "                (input_rearrange): Rearrange('b h (l d) -> b l h d', l=8)\n",
       "                (out_rearrange): Rearrange('b l h d -> b h (l d)')\n",
       "                (drop_output): Dropout(p=0.0, inplace=False)\n",
       "                (drop_weights): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Convolution(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (resnets): ModuleList(\n",
       "        (0): DiffusionUNetResnetBlock(\n",
       "          (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv1): Convolution(\n",
       "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (time_emb_proj): Linear(in_features=128, out_features=256, bias=True)\n",
       "          (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "          (conv2): Convolution(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Convolution(\n",
       "            (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (1): DiffusionUNetResnetBlock(\n",
       "          (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv1): Convolution(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (time_emb_proj): Linear(in_features=128, out_features=256, bias=True)\n",
       "          (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "          (conv2): Convolution(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (middle_block): CrossAttnMidBlock(\n",
       "    (resnet_1): DiffusionUNetResnetBlock(\n",
       "      (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "      (nonlinearity): SiLU()\n",
       "      (conv1): Convolution(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (time_emb_proj): Linear(in_features=128, out_features=256, bias=True)\n",
       "      (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "      (conv2): Convolution(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (skip_connection): Identity()\n",
       "    )\n",
       "    (attention): SpatialTransformer(\n",
       "      (norm): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "      (proj_in): Convolution(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (transformer_blocks): ModuleList(\n",
       "        (0): DiffusionUNetTransformerBlock(\n",
       "          (attn1): SABlock(\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (to_q): Linear(in_features=256, out_features=256, bias=False)\n",
       "            (to_k): Linear(in_features=256, out_features=256, bias=False)\n",
       "            (to_v): Linear(in_features=256, out_features=256, bias=False)\n",
       "            (qkv): Identity()\n",
       "            (input_rearrange): Rearrange('b h (l d) -> b l h d', l=8)\n",
       "            (out_rearrange): Rearrange('b l h d -> b h (l d)')\n",
       "            (drop_output): Dropout(p=0.0, inplace=False)\n",
       "            (drop_weights): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ff): MLPBlock(\n",
       "            (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (linear2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (fn): GEGLU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (attn2): CrossAttentionBlock(\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (to_q): Linear(in_features=256, out_features=256, bias=False)\n",
       "            (to_k): Linear(in_features=1, out_features=256, bias=False)\n",
       "            (to_v): Linear(in_features=1, out_features=256, bias=False)\n",
       "            (input_rearrange): Rearrange('b h (l d) -> b l h d', l=8)\n",
       "            (out_rearrange): Rearrange('b l h d -> b h (l d)')\n",
       "            (drop_output): Dropout(p=0.0, inplace=False)\n",
       "            (drop_weights): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (proj_out): Convolution(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (resnet_2): DiffusionUNetResnetBlock(\n",
       "      (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "      (nonlinearity): SiLU()\n",
       "      (conv1): Convolution(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (time_emb_proj): Linear(in_features=128, out_features=256, bias=True)\n",
       "      (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "      (conv2): Convolution(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (skip_connection): Identity()\n",
       "    )\n",
       "  )\n",
       "  (up_blocks): ModuleList(\n",
       "    (0): CrossAttnUpBlock(\n",
       "      (attentions): ModuleList(\n",
       "        (0-2): 3 x SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "          (proj_in): Convolution(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): DiffusionUNetTransformerBlock(\n",
       "              (attn1): SABlock(\n",
       "                (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (to_q): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (to_k): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (to_v): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (qkv): Identity()\n",
       "                (input_rearrange): Rearrange('b h (l d) -> b l h d', l=8)\n",
       "                (out_rearrange): Rearrange('b l h d -> b h (l d)')\n",
       "                (drop_output): Dropout(p=0.0, inplace=False)\n",
       "                (drop_weights): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (ff): MLPBlock(\n",
       "                (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "                (linear2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "                (fn): GEGLU()\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (attn2): CrossAttentionBlock(\n",
       "                (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (to_q): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (to_k): Linear(in_features=1, out_features=256, bias=False)\n",
       "                (to_v): Linear(in_features=1, out_features=256, bias=False)\n",
       "                (input_rearrange): Rearrange('b h (l d) -> b l h d', l=8)\n",
       "                (out_rearrange): Rearrange('b l h d -> b h (l d)')\n",
       "                (drop_output): Dropout(p=0.0, inplace=False)\n",
       "                (drop_weights): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Convolution(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (resnets): ModuleList(\n",
       "        (0-1): 2 x DiffusionUNetResnetBlock(\n",
       "          (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv1): Convolution(\n",
       "            (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (time_emb_proj): Linear(in_features=128, out_features=256, bias=True)\n",
       "          (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "          (conv2): Convolution(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Convolution(\n",
       "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (2): DiffusionUNetResnetBlock(\n",
       "          (norm1): GroupNorm(32, 384, eps=1e-06, affine=True)\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv1): Convolution(\n",
       "            (conv): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (time_emb_proj): Linear(in_features=128, out_features=256, bias=True)\n",
       "          (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "          (conv2): Convolution(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Convolution(\n",
       "            (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (upsampler): WrappedUpsample(\n",
       "        (upsample_non_trainable): Upsample(scale_factor=(2.0, 2.0), mode='nearest')\n",
       "        (postconv): Convolution(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): CrossAttnUpBlock(\n",
       "      (attentions): ModuleList(\n",
       "        (0-2): 3 x SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "          (proj_in): Convolution(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): DiffusionUNetTransformerBlock(\n",
       "              (attn1): SABlock(\n",
       "                (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (to_q): Linear(in_features=128, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=128, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=128, out_features=128, bias=False)\n",
       "                (qkv): Identity()\n",
       "                (input_rearrange): Rearrange('b h (l d) -> b l h d', l=4)\n",
       "                (out_rearrange): Rearrange('b l h d -> b h (l d)')\n",
       "                (drop_output): Dropout(p=0.0, inplace=False)\n",
       "                (drop_weights): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (ff): MLPBlock(\n",
       "                (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "                (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
       "                (fn): GEGLU()\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (attn2): CrossAttentionBlock(\n",
       "                (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (to_q): Linear(in_features=128, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=1, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=1, out_features=128, bias=False)\n",
       "                (input_rearrange): Rearrange('b h (l d) -> b l h d', l=4)\n",
       "                (out_rearrange): Rearrange('b l h d -> b h (l d)')\n",
       "                (drop_output): Dropout(p=0.0, inplace=False)\n",
       "                (drop_weights): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Convolution(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (resnets): ModuleList(\n",
       "        (0): DiffusionUNetResnetBlock(\n",
       "          (norm1): GroupNorm(32, 384, eps=1e-06, affine=True)\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv1): Convolution(\n",
       "            (conv): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (time_emb_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "          (conv2): Convolution(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Convolution(\n",
       "            (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (1): DiffusionUNetResnetBlock(\n",
       "          (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv1): Convolution(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (time_emb_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "          (conv2): Convolution(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Convolution(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (2): DiffusionUNetResnetBlock(\n",
       "          (norm1): GroupNorm(32, 192, eps=1e-06, affine=True)\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv1): Convolution(\n",
       "            (conv): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (time_emb_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "          (conv2): Convolution(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Convolution(\n",
       "            (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (upsampler): WrappedUpsample(\n",
       "        (upsample_non_trainable): Upsample(scale_factor=(2.0, 2.0), mode='nearest')\n",
       "        (postconv): Convolution(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): CrossAttnUpBlock(\n",
       "      (attentions): ModuleList(\n",
       "        (0-2): 3 x SpatialTransformer(\n",
       "          (norm): GroupNorm(32, 64, eps=1e-06, affine=True)\n",
       "          (proj_in): Convolution(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): DiffusionUNetTransformerBlock(\n",
       "              (attn1): SABlock(\n",
       "                (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "                (to_q): Linear(in_features=64, out_features=64, bias=False)\n",
       "                (to_k): Linear(in_features=64, out_features=64, bias=False)\n",
       "                (to_v): Linear(in_features=64, out_features=64, bias=False)\n",
       "                (qkv): Identity()\n",
       "                (input_rearrange): Rearrange('b h (l d) -> b l h d', l=2)\n",
       "                (out_rearrange): Rearrange('b l h d -> b h (l d)')\n",
       "                (drop_output): Dropout(p=0.0, inplace=False)\n",
       "                (drop_weights): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (ff): MLPBlock(\n",
       "                (linear1): Linear(in_features=64, out_features=512, bias=True)\n",
       "                (linear2): Linear(in_features=256, out_features=64, bias=True)\n",
       "                (fn): GEGLU()\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (attn2): CrossAttentionBlock(\n",
       "                (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "                (to_q): Linear(in_features=64, out_features=64, bias=False)\n",
       "                (to_k): Linear(in_features=1, out_features=64, bias=False)\n",
       "                (to_v): Linear(in_features=1, out_features=64, bias=False)\n",
       "                (input_rearrange): Rearrange('b h (l d) -> b l h d', l=2)\n",
       "                (out_rearrange): Rearrange('b l h d -> b h (l d)')\n",
       "                (drop_output): Dropout(p=0.0, inplace=False)\n",
       "                (drop_weights): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Convolution(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (resnets): ModuleList(\n",
       "        (0): DiffusionUNetResnetBlock(\n",
       "          (norm1): GroupNorm(32, 192, eps=1e-06, affine=True)\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv1): Convolution(\n",
       "            (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (time_emb_proj): Linear(in_features=128, out_features=64, bias=True)\n",
       "          (norm2): GroupNorm(32, 64, eps=1e-06, affine=True)\n",
       "          (conv2): Convolution(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Convolution(\n",
       "            (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (1): DiffusionUNetResnetBlock(\n",
       "          (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv1): Convolution(\n",
       "            (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (time_emb_proj): Linear(in_features=128, out_features=64, bias=True)\n",
       "          (norm2): GroupNorm(32, 64, eps=1e-06, affine=True)\n",
       "          (conv2): Convolution(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Convolution(\n",
       "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (2): DiffusionUNetResnetBlock(\n",
       "          (norm1): GroupNorm(32, 96, eps=1e-06, affine=True)\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv1): Convolution(\n",
       "            (conv): Conv2d(96, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (time_emb_proj): Linear(in_features=128, out_features=64, bias=True)\n",
       "          (norm2): GroupNorm(32, 64, eps=1e-06, affine=True)\n",
       "          (conv2): Convolution(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Convolution(\n",
       "            (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (upsampler): WrappedUpsample(\n",
       "        (upsample_non_trainable): Upsample(scale_factor=(2.0, 2.0), mode='nearest')\n",
       "        (postconv): Convolution(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): UpBlock(\n",
       "      (resnets): ModuleList(\n",
       "        (0): DiffusionUNetResnetBlock(\n",
       "          (norm1): GroupNorm(32, 96, eps=1e-06, affine=True)\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv1): Convolution(\n",
       "            (conv): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (time_emb_proj): Linear(in_features=128, out_features=32, bias=True)\n",
       "          (norm2): GroupNorm(32, 32, eps=1e-06, affine=True)\n",
       "          (conv2): Convolution(\n",
       "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Convolution(\n",
       "            (conv): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (1-2): 2 x DiffusionUNetResnetBlock(\n",
       "          (norm1): GroupNorm(32, 64, eps=1e-06, affine=True)\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv1): Convolution(\n",
       "            (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (time_emb_proj): Linear(in_features=128, out_features=32, bias=True)\n",
       "          (norm2): GroupNorm(32, 32, eps=1e-06, affine=True)\n",
       "          (conv2): Convolution(\n",
       "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Convolution(\n",
       "            (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (out): Sequential(\n",
       "    (0): GroupNorm(32, 32, eps=1e-06, affine=True)\n",
       "    (1): SiLU()\n",
       "    (2): Convolution(\n",
       "      (conv): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LDM_state_dict = torch.load('Checkpoints_conditioned/trained_LDM_epoch_432.pt', mmap=True, weights_only=True)\n",
    "LDM_model.load_state_dict(LDM_state_dict, assign=True)\n",
    "LDM_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7f63b33b-d333-425f-98e4-3bc00a672257",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1502339/2798438554.py:25: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=True):\n",
      "100%|| 1000/1000 [01:16<00:00, 13.14it/s]\n",
      "100%|| 1000/1000 [01:16<00:00, 13.13it/s]\n",
      "100%|| 1000/1000 [01:16<00:00, 13.13it/s]\n",
      "100%|| 1000/1000 [01:16<00:00, 13.13it/s]\n",
      "100%|| 1000/1000 [01:16<00:00, 13.12it/s]\n",
      "100%|| 1000/1000 [01:16<00:00, 13.13it/s]\n",
      "100%|| 1000/1000 [01:16<00:00, 13.12it/s]\n",
      "100%|| 1000/1000 [01:16<00:00, 13.13it/s]\n",
      " 91%|       | 910/1000 [01:09<00:06, 13.12it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m diag \u001b[38;5;241m=\u001b[39m diag\u001b[38;5;241m.\u001b[39munsqueeze(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     29\u001b[0m diag \u001b[38;5;241m=\u001b[39m diag\u001b[38;5;241m.\u001b[39munsqueeze(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 30\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43minferer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_noise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnoise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiffusion_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLDM_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mldm_scheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcrossattn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconditioning\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdiag\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m image \u001b[38;5;241m=\u001b[39m image[:, :, \u001b[38;5;241m2\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m     32\u001b[0m image \u001b[38;5;241m=\u001b[39m vAE_model\u001b[38;5;241m.\u001b[39mdecode(image)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/monai/inferers/inferer.py:881\u001b[0m, in \u001b[0;36mDiffusionInferer.sample\u001b[0;34m(self, input_noise, diffusion_model, scheduler, save_intermediates, intermediate_steps, conditioning, mode, verbose, seg)\u001b[0m\n\u001b[1;32m    876\u001b[0m     model_output \u001b[38;5;241m=\u001b[39m diffusion_model(\n\u001b[1;32m    877\u001b[0m         model_input, timesteps\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mTensor((t,))\u001b[38;5;241m.\u001b[39mto(input_noise\u001b[38;5;241m.\u001b[39mdevice), context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    878\u001b[0m     )\n\u001b[1;32m    879\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    880\u001b[0m     model_output \u001b[38;5;241m=\u001b[39m diffusion_model(\n\u001b[0;32m--> 881\u001b[0m         image, timesteps\u001b[38;5;241m=\u001b[39m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_noise\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m, context\u001b[38;5;241m=\u001b[39mconditioning\n\u001b[1;32m    882\u001b[0m     )\n\u001b[1;32m    884\u001b[0m \u001b[38;5;66;03m# 2. compute previous image: x_t -> x_t-1\u001b[39;00m\n\u001b[1;32m    885\u001b[0m image, _ \u001b[38;5;241m=\u001b[39m scheduler\u001b[38;5;241m.\u001b[39mstep(model_output, t, image)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "save_dir = \"./synthetic_non_conditional\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "vAE_model.eval()\n",
    "LDM_model.eval()\n",
    "\n",
    "np_imgs = np.zeros([1, 1, 240, 240])\n",
    "\n",
    "list_diag = [torch.tensor(0.0), torch.tensor(0.5), torch.tensor(1.0)]\n",
    "\n",
    "for k in range(3):\n",
    "    for i in range(5):\n",
    "        with torch.no_grad():\n",
    "            noise = torch.randn((128, 1, 64, 64))\n",
    "            noise = noise.to(device)\n",
    "            ldm_scheduler.set_timesteps(num_inference_steps=1000)\n",
    "            with autocast(enabled=True):\n",
    "                diagnosis = list_diag[k]\n",
    "                diag = diagnosis.unsqueeze(dim=-1)\n",
    "                diag = diag.unsqueeze(dim=-1)\n",
    "                diag = diag.unsqueeze(dim=-1).to(device)\n",
    "                image = inferer.sample(input_noise=noise, diffusion_model=LDM_model, scheduler=ldm_scheduler, mode=\"crossattn\", conditioning=diag)\n",
    "                image = image[:, :, 2:-2, 2:-2]\n",
    "                image = vAE_model.decode(image).cpu().detach().numpy()\n",
    "    \n",
    "            for j in range(image.shape[0]):\n",
    "                img = image[j]  # Shape: [C, H, W]\n",
    "                # Convert to [H, W] or [H, W, C] if needed\n",
    "                if img.shape[0] == 1:\n",
    "                    img = img[0]  # [H, W]\n",
    "                else:\n",
    "                    img = np.transpose(img, (1, 2, 0))  # [H, W, C]\n",
    "    \n",
    "                \n",
    "                nifti_img = nib.Nifti1Image(np.float32(img), affine=np.eye(4))\n",
    "                nib.save(nifti_img, f\"{save_dir}/img_{i}_{j}_diag{k}.nii.gz\")\n",
    "\n",
    "fake_images = np_imgs[1:]\n",
    "print(np.shape(fake_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "00c4bf68-c7fd-4109-abd0-eddbd2c84cdd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1262, 1, 240, 240)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_dir = 'TrainingData_Key/slices_40_anon/'\n",
    "df = pd.read_csv('TrainingData_Key/data_key_anon.csv')\n",
    "\n",
    "np_imgs = np.zeros([1,1,240,240])\n",
    "\n",
    "df['Linked_Files_Anon'] = df['Linked_Files_Anon'].apply(lambda x: os.path.join(data_dir, x))\n",
    "\n",
    "diags = [0.0, 0.5, 1.0]\n",
    "\n",
    "for i in range(3):\n",
    "    current_diag = diags[i]\n",
    "    current_df = df[df['DX_encoded']==current_diag]\n",
    "    for idx, row in current_df.iterrows():\n",
    "        file_name = row['Linked_Files_Anon']\n",
    "        nii_img = nib.load(file_name)\n",
    "        real_images = nii_img.get_fdata()\n",
    "        np_imgs = np.concatenate((np_imgs, np.expand_dims(np.expand_dims(real_images, axis=0), axis=0)), axis=0)\n",
    "\n",
    "real_images = np_imgs[1:]\n",
    "print(np.shape(real_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c24fa62-1900-4d23-8c35-17350fb2a86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(fake_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10e21c1-77e3-431a-b740-0d75a458b687",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.image.fid import FrechetInceptionDistance\n",
    "\n",
    "fid = FrechetInceptionDistance(normalize=True)\n",
    "fid.update(real_images, real=True)\n",
    "fid.update(fake_images, real=False)\n",
    "\n",
    "print(f\"FID: {float(fid.compute())}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
